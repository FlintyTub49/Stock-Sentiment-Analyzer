{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EbQ4x_htrxk"
   },
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3CSoyiDcj_ND"
   },
   "outputs": [],
   "source": [
    "!pip install easyOCR\n",
    "!pip install catboost\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle as pk\n",
    "from skimage.measure import compare_ssim\n",
    "import argparse\n",
    "import imutils\n",
    "import statistics\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords # Words which do not contribute to the sentiment analysis\n",
    "from nltk.tokenize import word_tokenize # Separating sentences in different components, every word and punctuation\n",
    "from nltk.stem import LancasterStemmer # Converts the words to root words which might or might not make sense\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras import models, layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "\n",
    "nltk.download()\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woJE2THIupkX"
   },
   "source": [
    "## Getting Data From Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnGRUo1fvOwZ"
   },
   "source": [
    "### Read Text in Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TOZw7f2Tuo6B"
   },
   "outputs": [],
   "source": [
    "def doOCR(img):\n",
    "  output = reader.readtext(img)\n",
    "  words = []\n",
    "  for i in range(len(output)):\n",
    "    words.append(output[i][1])\n",
    "  return words, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4xFrR71vQ-O"
   },
   "source": [
    "### Make Bounding Box Around The Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFGo1YHZvXPO"
   },
   "outputs": [],
   "source": [
    "def boundText(output, img):\n",
    "  cord = [output[i][0] for i in range(len(output))]\n",
    "  start = []\n",
    "  end = []\n",
    "  for i in range(len(cord)):\n",
    "    x_min, y_min = [min(loc) for loc in zip(*cord[i])]\n",
    "    x_max, y_max = [max(loc) for loc in zip(*cord[i])]\n",
    "    temp1 = [x_min, y_min]\n",
    "    temp2 = [x_max, y_max] \n",
    "    start.append(temp1)\n",
    "    end.append(temp2)\n",
    "  fig = plt.figure(figsize = (15, 12))\n",
    "  for n, i in enumerate(zip(start, end)):\n",
    "    cv2.rectangle(img, (start[n][0], start[n][1]), (end[n][0], end[n][1]), (0, 0, 0), 4)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IypxVnYQd7dP"
   },
   "source": [
    "## Detecting Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yu_zXDPipdYX"
   },
   "source": [
    "### Loading The Set of Positive and Negative Words In Their Root Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NJ5e_nadn45m"
   },
   "outputs": [],
   "source": [
    "def load_data(pos, neg, info):\n",
    "  stemmer = LancasterStemmer()\n",
    "  pos_words, neg_words = open(pos, 'r'), open(neg, 'r')\n",
    "  pos_words, neg_words = pos_words.read().lower().split(), neg_words.read().lower().split()\n",
    "\n",
    "  positive, negative = [], []\n",
    "  for i in pos_words: positive.append(stemmer.stem(i[:-1]))\n",
    "  for i in neg_words: negative.append(stemmer.stem(i[:-1]))\n",
    "\n",
    "  data = open(info, 'r')\n",
    "  data = data.readlines()\n",
    "  train, label = [], []\n",
    "  for i in data: \n",
    "    temp = i[:-2].lower().split()\n",
    "    label.append(i[-2])\n",
    "    headline = ''\n",
    "    for j in temp:\n",
    "      headline = headline + stemmer.stem(j) + ' '\n",
    "    train.append(headline)\n",
    "\n",
    "  train.extend(positive); label.extend([1 for i in positive])\n",
    "  train.extend(negative); label.extend([0 for i in negative])\n",
    "\n",
    "  data = pd.DataFrame()\n",
    "  data['headlines'] = train\n",
    "  data['label'] = label\n",
    "  data['label'] = data['label'].astype('int64')\n",
    "  return positive, negative, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuKTFHUunNDl"
   },
   "source": [
    "### Tokenizing, Removing Punctuation & Stopwords and Lemmatizing The Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ouqg0R5TgQMb"
   },
   "outputs": [],
   "source": [
    "def preprocess(words):\n",
    "  stuff_to_be_removed = list(stopwords.words('english'))+list(punctuation)\n",
    "  stemmer = LancasterStemmer()\n",
    "\n",
    "  final_headlines = []\n",
    "  for i in range(len(words)):\n",
    "    headline = word_tokenize(words[i].lower())\n",
    "    headline = [stemmer.stem(y) for y in headline if y not in stuff_to_be_removed]\n",
    "    j = \" \".join(headline)\n",
    "    final_headlines.append(j)\n",
    "\n",
    "  return final_headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CxkqDQt_Jff"
   },
   "source": [
    "### Keeping Only Relevant Text from Each Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AzXQDVeu9Tkq"
   },
   "outputs": [],
   "source": [
    "def filterImportant(final_headlines, positive, negative):\n",
    "  final = []\n",
    "  for i in final_headlines:\n",
    "    temp = i.split()\n",
    "    flag = 0\n",
    "    for j in temp:\n",
    "      if j in positive or j in negative: flag+=1\n",
    "    if flag: final.append(i)\n",
    "  return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TmpbyK7b0Dj"
   },
   "source": [
    "## Actual Code Running - Per Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vB9IPXhJauHF"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('/content/Positive News.png')\n",
    "\n",
    "# DoOCR Function Returns words or phrases in the image and output which includes the coordinates of the text\n",
    "words, output = doOCR(img)\n",
    "\n",
    "# A function which uses the output of the OCR engine to return image with text box made around it\n",
    "img = boundText(output, img)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "''' \n",
    "Loading Data to Filter out relevant text from image and used for Model Building as well \n",
    "Takes 3 inputs \n",
    "- File with positive words about stock which GENERALLY indicate growing stock - Used for filtering and prediction\n",
    "- File with negative words about stock which GENERALLY indicate declining stock - Used for filtering and prediction\n",
    "- File with sample headlines to help train the model - Only Used for Prediction\n",
    "'''\n",
    "positive, negative, data = load_data('/content/Positive Words.txt', '/content/Negative Words.txt', # Filtering\n",
    "                                     '/content/Headlines.txt') # Only to create model, not necessary while running\n",
    "\n",
    "# Preprocess the words obtained from the frame - Takes input as a LIST OF STRINGS\n",
    "headlines = preprocess(words)\n",
    "\n",
    "# Filtering out the irrelevant headlines which say nothing about the stock\n",
    "headlines = filterImportant(headlines, positive, negative)\n",
    "print('Important Headlines', headlines)\n",
    "\n",
    "# Loading The TFIDF Vectorizer Model and Sentiment Analyzer Model used while training the model\n",
    "vec = pk.load(open('transformer.pkl', 'rb'))\n",
    "sent = pk.load(open('analyzer.pkl', 'rb'))\n",
    "\n",
    "# Detecting the sentiment of final headlines\n",
    "headlines = vec.transform(headlines)\n",
    "print('Prediction:', sent.predict(headlines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RQgaCltSKQp"
   },
   "source": [
    "## Working With Video - MAIN FUNCTION IN THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PAwZJ-IVBnp"
   },
   "source": [
    "### Sentiment for Every Frame Captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2wV71JhQRe7"
   },
   "outputs": [],
   "source": [
    "def newsSentiment(img):\n",
    "  words, output = doOCR(img)\n",
    "  img = boundText(output, img)\n",
    "  \n",
    "  headlines = preprocess(words)\n",
    "  headlines = filterImportant(headlines, positive, negative)\n",
    "  print(headlines)\n",
    "  \n",
    "  headlines = vec.transform(headlines)\n",
    "  pred = statistics.median(sent.predict(headlines))\n",
    "  # cv2.putText(img, pred, (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_4)\n",
    "  if pred: cv2.rectangle(img, (0, 0), (30, 30), (255, 255, 255), -1)\n",
    "  else: cv2.rectangle(img, (0, 0), (30, 30), (0, 0, 0), -1)\n",
    "  \n",
    "  return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQnbVDxAVJjN"
   },
   "source": [
    "### Saving SIGNIFICANTLY different Frames from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CtW5gNkvS6EI"
   },
   "outputs": [],
   "source": [
    "def save_frames(video, folder):\n",
    "  cap = cv2.VideoCapture(video)\n",
    "\n",
    "  if not (cap.isOpened()):\n",
    "    print(\"Error Reading Video\")\n",
    "    return\n",
    "\n",
    "  _, frame1 = cap.read()\n",
    "  files = folder + '/frame0' + '.jpg'\n",
    "  i = 1\n",
    "  cv2.imwrite(files, frame1)\n",
    "\n",
    "  while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "      grayA = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "      grayB = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "      \n",
    "      score, diff = compare_ssim(grayA, grayB, full=True)\n",
    "      diff = (diff * 255).astype(\"uint8\")\n",
    "      \n",
    "      if score < 0.8: # This parameter can be adjusted to capture more changes in consecutive frames\n",
    "        files = folder + '/frame'+ str(i) +'.jpg'\n",
    "        i += 1\n",
    "        cv2.imwrite(files, frame2)\n",
    "        frame1 = frame2\n",
    "      \n",
    "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    else: ## Waiting for the video to be over\n",
    "      break\n",
    "\n",
    "  cap.release()\n",
    "  cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUio57HvVa25"
   },
   "source": [
    "### Calling All Functions - MAIN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IbzZNEPBRmXI"
   },
   "outputs": [],
   "source": [
    "vec = pk.load(open('transformer.pkl', 'rb'))\n",
    "sent = pk.load(open('analyzer.pkl', 'rb'))\n",
    "\n",
    "positive, negative, data = load_data('/content/Positive Words.txt', '/content/Negative Words.txt', \n",
    "                                     '/content/Headlines.txt')\n",
    "\n",
    "folder = '/content/frames'\n",
    "video = '/content/rest.mov'\n",
    "save_frames(video, folder)\n",
    "\n",
    "print('Captured Video')\n",
    "for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        '''\n",
    "        The following function will return the frame with all the text highlighted and a little square on top left of the screen\n",
    "        Black Square - Stock price will go down\n",
    "        White Square - Stock price will go up\n",
    "        '''\n",
    "        img = newsSentiment(img)\n",
    "        '''\n",
    "        Using plt.imshow for displaying image here as cv2.imshow doesn't work on colab, if running on local system, cv2.imshow command can \n",
    "        be used to see all the frames one after the other like a video. Command is commented out below\n",
    "        '''\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # OR cv2.imshow('News', cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "woJE2THIupkX",
    "IypxVnYQd7dP",
    "XQnbVDxAVJjN"
   ],
   "name": "Maybe Internship.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
